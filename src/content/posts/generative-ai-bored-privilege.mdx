---
title: "Generative AI bores me to tears and that's a privileged stance"
description: "I can't know how to hear anymore about chatbots."
published: true
pubDate: '20 Dec 2025'
tags: ["AI", "tech"]
---

import IcebergNotes from '../../components/IcebergNotes.astro';

The gaps between having an idea burrow its way into my brain and putting it in a blog post are getting shorter. The last one about [loneliness in blogging and online spaces](/posts/thoughts-loneliness-blogging/) took me weeks and this one, about my boredom with generative AI, has taken... weeks but less weeks so it's an improvement.

I wanted to talk about my general mental fatigue and emotional malaise over all things generative AI. And while that will form the basis of this post, I read a very good article that made me realise that this tiredness is a privileged perspective.<sup>[<a href="#in-1">1</a>]</sup>

## Privilege in the era of AI

On 3rd December, Josh Collinsworth wrote an article titled "[AI optimism is a class privilege](https://joshcollinsworth.com/blog/sloptimism)". In it, he outlined the idea of AI optimism requireing a level of privilege that a lot of people can't afford. It's also something of a ticking time bomb fallacy due to mass proliferation.

> That’s the thing about being bullish on AI: to focus on its benefits to you, you’re forced to ignore its costs to others.

As with any good article I find, there are tons of quotables which means you should read the whole thing instead. Josh touched on a lot of topics that I had been thinking about over the last few years but not from this perspective.

I don't confront people about their AI optimism because it'd be a futile task and seem like an unprovoked attack. I have an itchy trigger finger with this tech, knowing what it's been used for over and over and over again, but a common response to seemingly _any_ AI use case is "interesting!" and I have to ask: which part is interesting, exactly?

## The Generation Game where everybody loses

I've mentioned before how we should be more specific about what AI tech we're referring to in our rhetoric since AI is an umbrella term ([and a lot like an orange](/posts/ai-is-a-lot-like-an-orange/). This helps at a relatively basic level when you're trying to figure out the difference between an AI-generated image and an image enhanced using AI tech (see: [Will Smith concert pics](https://www.reddit.com/r/Fauxmoi/comments/1n2ma6o/will_smiths_concert_crowds_are_real_but_ai_is/))

But Josh's article made me think if the distinctions make a difference in terms of the outcomes. Popular LLMs are made by the same 5 companies who are destroying the planet. Open source models don't guzzle as much electricity and water and can be run locally but they're not as powerful so get left behind in peoples' minds and compute power is compute power at the end of the day—electricity will increase no matter whose power you use. As for harms, they scale depending on the model but you're still at risk of exposure. And what about the idea of use as endorsement? It's not out of the realms of possibility that advocating for open source models could lead someone to try out a proprietry model due to the former's weaker output and find their "sweet spot".

## Single bored computing

All of the above swirl around in my mind whenever I see a new generative AI "thing". It could be at work, on social media, or in a blog post I've read by someone I actually respect (even if they write about people that I don't respect). And I'm bored. I'm so so bored. To the point that it actually makes me a little queasy and I ache a little.

And the reason why I'm so bored is because none of this remotely interests me. It's all about "context engineering" and make it look like they're putting in a great deal of thought into the models which allegedly put a great deal of thought into the outputs. But it's the blind leading the blind. If something works for you, it might not work elsewhere or it could be improved in some way but you'd never know since you stopped once it "worked".

The evangelising makes me want to take my brain out and wash it with soap and water (I want to keep the wrinkles in tact so I didn't opt for smoothing in this metaphor). Nothing here is new or original. Every idea is just querying a machine instead of asking a human and paying them if that's what you should have been doing. A friend of mine reminded me that perhaps the idea wasn't to make AI tech successful and bring us AGI (whatever that means anymore) but to make sure that humans don't get paid for labour at the biggest scale in history. With that, they're doing well. Even if companies are losing money in the process, it's recoverable. For regular folks, it isn't—at least not in the same way.

## Thoughts and actions

And again, I'm back to battling between finding the whole thing tedious and asking myself whether that's helpful or meaningul. Who cares if I'm bored if I'm still using the tech and contributing to all this mess? I think I've mentioned it before in another blog but I'm surprised more of my friends haven't disconnected from me (more than usual). I've been fairly vocal in my criticisms but I use Gemini at work (not mandatory but it's heavily promoted) and dip into Gemini sometimes for code troubleshooting when I can't find the answer in docs or Stack Overflow.

The one area I do enjoy in all of this is around embeddings and NLP. I think they're cool and lean more towards machine learning techniques than the kind of generative AI that most general consumers are used to. And they've been in use long before this boom with search engines and other related tech. That's not to say that they are immune to biases and harms such as most models being heavily Anglocentric but it's as far away from the really bad stuff as I can short of stopping my use altogether.

## Professional assassination?

Whenever there are chats at work about AI, I'm usually the one posting cautionary tales and meta-opinions on why critical thinking is important. Early on, I did a webinar where I said similar things and I've even gone as far as saying AI should be a last resort in processes. So maybe this post and others like it don't look so good from a professional perspective. Or maybe people are humouring me when they say "that's interesting" (lol) but push ahead anyway because I guess they can't slow down now or whatever the popular ideology is with this tech.

Who knows, maybe I'll lose my job over my posts instead of the tech itself. But I stand by my criticisms because I stand by people over technology and big tech companies performing harmful practices behind brands and pledges. If nobody listens to what I say or takes heed, I can at least say that I made my intentions and impacts clear and I can live with what I've said and done.

I will remain bored at the latest AI trend. I will continue to cringe when I see people in my direct field talk about all these things I feel like I _should_ know but don't want to because it'll plunge me deeper into places I don't want to go. And I'll keep using open source models to build embeddings for little personal projects like finding out which Monster Rancher monsters are similar to Pokémon based on embeddings of their names and descriptions. And as long as I stay alive and don't lose my job (yet???), those actions will be propped up by my privileges.

I guess I'll be okay. For now.

<IcebergNotes>
	<sup id="in-1">1</sup>Josh's article makes it quite clear, to me at least, that no one is immune and while I don't expect to lose my job tomorrow, I must assume that my chances of losing it are a non-zero value unless I <a href="/posts/no-reason-to-embrace-ai-in-seo/">"embrace it"</a>
</IcebergNotes>