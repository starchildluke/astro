---
title: "Morsel #26: vibe recursion"
description: "Garbage in, garbage out and back in again"
published: true
pubDate: '14 Sep 2025'
tags:
  - AI
  - vibes
  - tech
---

What if you wrote a prompt (Prompt n) that asked the LLM to write a better prompt (Prompt n+1) than this prompt (Prompt n) and to ask for a better prompt to ask for later (which would be Prompt n+3). And then you repeat the process over and over to see the results.

Would it become asymptotic and reach a point where it couldn't produce a "better" prompt or would it go wild and lose quality and meaning?