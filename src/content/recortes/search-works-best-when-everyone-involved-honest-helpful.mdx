---
title: 'search works best when everyone involved is honest and helpful'
description: "if this social contract breaks down, people at the bottom suffer the most"
published: true
pubDate: '20 Jan 2026'
tags:
  - SEO
  - tech
  - the Internet
---

import Lede from '../../components/Lede.astro';

<Lede>search works best when everyone involved is honest and helpful</Lede>. what i mean by that is someone accessing a search engine hopes to look for a thing and eventually find what they wanted. the expected length of that journey may differ depending on the age of the person (remember [Ask Jeeves](https://web.archive.org/web/20010917011311/http://www.askjeeves.com/)????) but you shouldn't assume _not_ to get what you wanted.

and yet nowadays that's a growing possibility. this isn't a post about "better search engines to use instead of Google" and i'm not saying Google isn't that bad actually either. but no matter which search engine you use, your experience will be vastly different. that's expected as Google has the biggest index so anyone else will have to prioritise specificity over depth. but because of generative AI and paid ads, search results are full of things you never asked for.

## trust fails

Google's AI Overviews are the bane of my existence as a user and a search professional. they're wrong a lot of the time and when they're not, they offer links to articles that don't really back up the data they've scraped. i'm the kind of person who goes out to do further research before taking someone's word for it (seriously, we should all go back to that. we can't be THAT busy where we can't click a few links and read moreâ€”[think! use your head!](https://www.youtube.com/clip/UgkxAPFnzHK0xRwBfOALoNwAS1Zvo_b8Enhc)). but they're everywhere and they likely won't leave unless something better/worse/different comes a long to take their place. those zero click soothsayers didn't see THIS one coming in 2019!

if you manage to come out of a search results page alive and you've clicked a link assuming that you'll get what you're after, i really hope that you have! sadly there's no guarantee as the second point of failure on a user journey is the Web itself. people are so AI-pilled these days that they feel the need to stuff their pages with AI-generated content and don't link to external sites for fear of losing the sacred juice of links (or, in a less sinister way, to avoid showing that they did no research and an LLM wrote the article). [boo these people!](https://www.youtube.com/watch?v=ddsZTFSfXaw) it's a minefield out there and i don't know how we're gonna fix it but that's a discussion for more knowledgeable people.

## help wanted

so i've referenced the two main steps in a user journey from query to results to picking one to hopefully getting that thing you wanted. at the moment, that journey is fraught with danger and it keeps getting worse. and to go back to the title of this blog, there's a lack of honesty and helpfulness. sure, Google had its helpful content update and has flagged sites as unhelpful and that tanked performance (rightly or wrongly; some sites still haven't recovered after fixing themselves up) but what of the sites that aren't helpful and got away with it? a lack of honesty at any point in your journey will cause the experience to break down. if you're giving advice and that advice came from a chatbot AND you don't tell anyone, that's bad.

it shouldn't matter that the advice was objectively good. you've made a moral choice to defer responsibility to a machine that spits out words based on lots of other stolen words. it's also based on probability. ask a different question or the same one a few times and you might get different answers. is that what you want to put out in the world? answers based on D&D dice throws?

## honesty is the best policy

what we need is to go back to doing the research, being honest about where information came from and what your intentions are, admitting if you got something wrong or if it's a work in progress, and going from there. search engines also need to prioritise giving an answer rooted in facts and not the probabilities of an LLM and perhaps not just presenting An Answer in the results pages with a tiny link back to where they **might** have got it from. i still find that practice disingenous and you can't change my mind.

i don't want us to go back to old search. i think using [LLMs for contextual understanding](https://en.wikipedia.org/wiki/BERT_(language_model)) has its merits (albeit with a lot of biases involved) but whatever we have now isn't it. what use is [E-E-A-T](https://developers.google.com/search/docs/fundamentals/creating-helpful-content) if i don't feel the T. or the E. or the other E. actually, not the A either. wow, that's the whole abbreviation! that's not G-O-O-D! and as for the alternatives, [they come with significant caveats too](/posts/some-brief-thoughts-on-search/). do i want to [pay a subscription fee](https://kagi.com/) for an approximation to the search experience i had a few years ago? that still feels janky to me, even if it's meant to work out for some people. i wonder what Jeeves is up to. maybe i should ask him.